#!/usr/bin/env python
# coding: utf-8

# ## 1. Import Library & Define Functions
# * í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
# * í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

# In[ ]:


import os
import time
import timm
import torch
import wandb
import random
import datetime
import numpy as np
import pandas as pd
import seaborn as sns
import torch.nn as nn
import albumentations as A
import matplotlib.pyplot as plt
from PIL import Image
from tqdm import tqdm
from timm.loss import LabelSmoothingCrossEntropy
from torch.optim import Adam
from torch.optim.lr_scheduler import CosineAnnealingLR
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from albumentations.pytorch import ToTensorV2
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay


# In[ ]:


# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.
SEED = 42
os.environ['PYTHONHASHSEED'] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.benchmark = True


# In[ ]:


# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
class ImageDataset(Dataset):
    def __init__(self, df, path, transform=None):
        self.df = df.values if isinstance(df, pd.DataFrame) else pd.read_csv(df).values
        self.path = path
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        name, target = self.df[idx]
        img = np.array(Image.open(os.path.join(self.path, name)))
        if self.transform:
            img = self.transform(image=img)['image']
        return img, target


# In[ ]:

from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler() # fold ë£¨í”„ ì „ì—ì„œ ì´ˆê¸°í™”í•´ì•¼ ì¬ì‚¬ìš© ê°€ëŠ¥

# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def train_one_epoch(loader, model, optimizer, loss_fn, device, epoch=None):
    model.train()
    train_loss = 0
    preds_list, targets_list = [], []

    pbar = tqdm(loader, desc=f"Train Epoch {epoch+1}" if epoch is not None else "Train")
    for image, targets in pbar:
        image, targets = image.to(device), targets.to(device)
        optimizer.zero_grad(set_to_none=True)

        # âœ… ìë™ í˜¼í•© ì •ë°€ë„ (AMP)
        with autocast(): # forward ì—°ì‚°ì„ ë°˜ì •ë°€ë„ë¡œ ê³„ì‚° (ë©”ëª¨ë¦¬ ì ˆì•½)
            preds = model(image)
            loss = loss_fn(preds, targets)

        # âœ… Scalerë¡œ ì—­ì „íŒŒ
        scaler.scale(loss).backward() # ì†ì‹¤ê°’ì„ ì•ˆì „í•˜ê²Œ ìŠ¤ì¼€ì¼ë§
        scaler.step(optimizer) # ì˜µí‹°ë§ˆì´ì € ì—…ë°ì´íŠ¸ ì‹œ overflow ë°©ì§€
        scaler.update() # ì˜µí‹°ë§ˆì´ì € ì—…ë°ì´íŠ¸ ì‹œ overflow ë°©ì§€
        
        train_loss += loss.item()
        preds_list.extend(preds.argmax(dim=1).cpu().numpy())
        targets_list.extend(targets.cpu().numpy())

    # ---- epochë³„ í‰ê·  ê³„ì‚° ----
    train_loss /= len(loader)
    train_acc = accuracy_score(targets_list, preds_list)
    train_f1 = f1_score(targets_list, preds_list, average='macro')

    # ---- wandb ë¡œê·¸ ê¸°ë¡ ----
    wandb.log({
        "train_loss": train_loss,
        "train_acc": train_acc,
        "train_f1": train_f1,
        "lr": optimizer.param_groups[0]["lr"],        # âœ… í•™ìŠµë¥  ë¡œê·¸ ì¶”ê°€
        "epoch": epoch + 1 if epoch is not None else 0
    })

    return {"train_loss": train_loss, "train_acc": train_acc, "train_f1": train_f1}


# Validationìš© í•¨ìˆ˜ ì¶”ê°€
def valid_one_epoch(loader, model, loss_fn, device, epoch=None, fold=None):
    model.eval()
    val_loss = 0
    preds_list, targets_list = [], []

    with torch.no_grad():
        pbar = tqdm(loader, desc=f"Valid Epoch {epoch+1}" if epoch is not None else "Valid")
        for image, targets in pbar:
            image, targets = image.to(device), targets.to(device)
            preds = model(image)
            loss = loss_fn(preds, targets)
            val_loss += loss.item()
            preds_list.extend(preds.argmax(dim=1).cpu().numpy())
            targets_list.extend(targets.cpu().numpy())

    val_loss /= len(loader)
    val_acc = accuracy_score(targets_list, preds_list)
    val_f1 = f1_score(targets_list, preds_list, average='macro')

    # ğŸŸ© 1ï¸âƒ£ Confusion Matrix ê³„ì‚°
    cm = confusion_matrix(targets_list, preds_list)

    # ğŸŸ© 2ï¸âƒ£ í´ë˜ìŠ¤ë³„ ì •í™•ë„ ê³„ì‚°
    class_acc = cm.diagonal() / cm.sum(axis=1)
    class_acc_dict = {f"class_{i}_acc": float(acc) for i, acc in enumerate(class_acc)}

    # ğŸŸ© 3ï¸âƒ£ ì‹œê°í™” ë° wandb ì—…ë¡œë“œ
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"Confusion Matrix - Fold {fold+1 if fold is not None else '?'} (Epoch {epoch+1})")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")

    # ---- wandb ë¡œê·¸ ê¸°ë¡ ----
    wandb.log({
        "val_loss": val_loss,
        "val_acc": val_acc,
        "val_f1": val_f1,
        **class_acc_dict,  # ğŸŸ© í´ë˜ìŠ¤ë³„ accë„ ê°™ì´ ê¸°ë¡
        "epoch": epoch + 1 if epoch is not None else 0,
        "confusion_matrix": wandb.Image(plt)  # ğŸŸ© ì‹œê°í™” ì´ë¯¸ì§€ ë¡œê·¸
    })
    plt.close()

    return {"val_loss": val_loss, "val_acc": val_acc, "val_f1": val_f1, "preds": preds_list, "targets": targets_list}


# ## 2. Hyper-parameters
# * í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.

# In[ ]:


# device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# data config
data_path = 'datasets_fin/'

# model config
# model_name = 'resnet34' # 'resnet50' 'efficientnet-b0', ...
# model_name = 'efficientnet_b3'
# model_name = 'convnext_tiny'
# model_name = 'vit_base_patch16_384'
# model_name = 'swin_base_patch4_window12_384'
# model_name = 'resnext50_32x4d'
model_name = 'resnext101_32x8d'

# training config
img_size = 384 # 224, 384, 640
LR = 1e-4 #  3e-4 < 1e-3
EPOCHS = 100
BATCH_SIZE = 32 # 32
num_workers = 4 # 4


# ## 3. Load Data
# * í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

# In[ ]:


# augmentationì„ ìœ„í•œ transform ì½”ë“œ
trn_transform = A.Compose([
    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    A.Resize(height=img_size, width=img_size),
    
    # --- ì‹¤ì œ Test domain ëŒ€ì‘ ì¦ê°• ---
    A.Rotate(limit=180, p=0.7),                     # íšŒì „
    A.HorizontalFlip(p=0.5),                        # ì¢Œìš° ë°˜ì „
    A.VerticalFlip(p=0.3),                          # ìƒí•˜ ë°˜ì „
    A.RandomResizedCrop(height=img_size, width=img_size, scale=(0.8, 1.0), p=0.4),  # í¬ë¡­
    A.MotionBlur(blur_limit=5, p=0.3),              # ë¸”ëŸ¬
    A.GaussNoise(var_limit=(10, 50), p=0.3),        # ë…¸ì´ì¦ˆ
    A.RandomBrightnessContrast(p=0.3),              # ë°ê¸°/ëŒ€ë¹„
    A.HueSaturationValue(p=0.2),                    # ìƒ‰ì¡° ë³€í˜• (ì¸ì‡„/ì¡°ëª… ì°¨ì´ ëŒ€ì‘)

    # ê¸°ë³¸ì ì¸ ë’¤ì§‘ê¸° + ì‚´ì§ íšŒì „ë§Œ
    # A.HorizontalFlip(p=0.5),
    # A.Rotate(limit=15, p=0.3),

    # ë„ˆë¬´ ì‹¬í•œ í¬ë¡­/ë…¸ì´ì¦ˆ/ë¸”ëŸ¬ëŠ” ì¼ë‹¨ ì œê±°
    # A.RandomBrightnessContrast(p=0.2),
    
    # images normalization
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    # numpy ì´ë¯¸ì§€ë‚˜ PIL ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
    ToTensorV2(),
])

# test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ
tst_transform = A.Compose([
    A.Resize(height=img_size, width=img_size),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])


# In[ ]:


# print("ì´ ì´ë¯¸ì§€ ìˆ˜:", len(os.listdir("../data/train_balanced")))
print("ì´ ì´ë¯¸ì§€ ìˆ˜:", len(os.listdir("../data/train_mod_balanced")))
# df = pd.read_csv("../data/train_balanced.csv")
df = pd.read_csv("../data/train_mod_balanced.csv")
print(df["target"].value_counts().sort_index())


# In[ ]:


# --- âœ… K-Fold splitìœ¼ë¡œ ë³€ê²½ ---
# train_df = pd.read_csv("../data/train_balanced.csv")
train_df = pd.read_csv("../data/train_mod_balanced.csv")

folds = 5
skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)

# âœ… progressive resizing í—¬í¼ ì¶”ê°€
def adjust_img_size(epoch):
    # ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ê³ ì •
    return 384
    # return 640
    # í´ë“œ ê¸°ë°˜
    # if fold < 2:
    #     return 384
    # elif fold < 4:
    #     return 512
    # else:
    #     return 640
    # ì—í¬í¬ ê¸°ë°˜
    # if epoch < 30:
    #     return 384
    # elif epoch < 45:
    #     return 512
    # else:
    #     return 640

def update_transforms(new_size):
    global trn_transform, tst_transform
    trn_transform = A.Compose([
        A.Resize(height=new_size, width=new_size),
        A.Rotate(limit=90, p=0.5),
        A.HorizontalFlip(p=0.5),
        A.RandomResizedCrop(height=new_size, width=new_size, scale=(0.9, 1.0), p=0.3),
        A.GaussNoise(var_limit=(10, 40), p=0.2),
        A.RandomBrightnessContrast(p=0.3),
        A.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

    tst_transform = A.Compose([
        A.Resize(height=new_size, width=new_size),
        A.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

# âœ… foldë³„ í•™ìŠµ ë£¨í”„
for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):
    new_size = adjust_img_size(fold)
    update_transforms(new_size)
    # print(f"\n===== Fold {fold+1}/{folds} =====")
    print(f"\n===== Fold {fold+1}/{folds} | ì´ë¯¸ì§€ í¬ê¸°: {new_size}px =====")

    trn_df = train_df.iloc[train_idx].reset_index(drop=True)
    val_df = train_df.iloc[val_idx].reset_index(drop=True)

    # trn_dataset = ImageDataset(trn_df, "../data/train_balanced/", transform=trn_transform)
    # val_dataset = ImageDataset(val_df, "../data/train_balanced/", transform=tst_transform)
    trn_dataset = ImageDataset(trn_df, "../data/train_mod_balanced/", transform=trn_transform)
    val_dataset = ImageDataset(val_df, "../data/train_mod_balanced/", transform=tst_transform)

    trn_loader = DataLoader(trn_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)

    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)
    optimizer = Adam(model.parameters(), lr=LR)
    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)
    
    loss_fn = nn.CrossEntropyLoss()
    # ìœ„ loss_fn = nn.CrossEntropyLoss() ì£¼ì„ì²˜ë¦¬ í•˜ê³  ì•„ë˜ ì£¼ì„ í’€ë©´ ë¼ë²¨ìŠ¤ë¬´ë”© ì‚¬ìš© ê°€ëŠ¥
    # loss_fn = LabelSmoothingCrossEntropy(smoothing=0.1)

    run_name = f"{model_name}_fold{fold+1}_{datetime.datetime.now().strftime('%m%d_%H%M')}"
    wandb.init(project="document-type-classification", name=run_name)

    # âœ… Early Stopping ì„¤ì •
    best_val_f1 = 0
    patience = 15     # ê°œì„  ì•ˆ ë˜ëŠ” ì—í­ì´ 5ë²ˆ ì—°ì†ì´ë©´ stop
    counter = 0 
    
    for epoch in range(EPOCHS):
        torch.cuda.empty_cache()  # âœ… ìºì‹œ í•´ì œ
        print(f"\n[Fold {fold+1}] [Epoch {epoch+1}]")  # í¬ê¸° ê³ ì •
        all_preds, all_targets = [], []

        train_metrics = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device, epoch=epoch)
        val_metrics = valid_one_epoch(val_loader, model, loss_fn, device=device, epoch=epoch, fold=fold)
        all_preds.extend(val_metrics["preds"])
        all_targets.extend(val_metrics["targets"])
        
        scheduler.step()

        val_f1 = val_metrics["val_f1"]

        # âœ… best ëª¨ë¸ ì €ì¥ ë¡œì§
        if val_f1 > best_val_f1:
            best_val_f1 = val_f1
            torch.save(model.state_dict(), f"{model_name}_fold{fold+1}_best.pt")
            print(f"ğŸŒŸ ê°œì„ ë¨! ëª¨ë¸ ì €ì¥ (Val F1={val_f1:.4f})")
            counter = 0  # patience ì´ˆê¸°í™”
        else:
            counter += 1
            print(f"âš ï¸ ê°œì„  ì—†ìŒ ({counter}/{patience})")

        if counter >= patience:
            print(f"â¹ï¸ Early Stopping ë°œë™ (ìµœëŒ€ {patience}íšŒ ë¯¸ê°œì„ )")
            break
        
        print(
            f"[Fold {fold+1}] [Epoch {epoch+1}/{EPOCHS}] "
            f"Train F1: {train_metrics['train_f1']:.4f}, "
            f"Val F1: {val_metrics['val_f1']:.4f}, "
            f"LR: {optimizer.param_groups[0]['lr']:.8f}"
        )

    model_path = f"{model_name}_fold{fold+1}.pt"
    torch.save(model.state_dict(), model_path)
    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
    wandb.finish()

# ê° foldì˜ validation ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³  ë³‘í•©í•´ì„œ confusion matrix ë³´ì—¬ì£¼ê¸°
cm_total = confusion_matrix(all_targets, all_preds)
sns.heatmap(cm_total, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix - All Folds")
plt.show()

# ## 4. Train Model
# * ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.

# # 5. Inference & Save File
# * í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.

# In[ ]:


# --- âœ… ëª¨ë“  Fold í•™ìŠµ ì™„ë£Œ í›„ Inference ë‹¨ê³„ ---
print("\n===== TTA Inference ì‹œì‘ =====")

# âœ… test dataset / loader ì •ì˜
tst_dataset = ImageDataset(
    "../data/sample_submission.csv",
    "../data/test/",
    transform=tst_transform
)
tst_loader = DataLoader(tst_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

# âœ… foldë³„ ëª¨ë¸ ê²½ë¡œ ì§€ì • (ì´ë¯¸ í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ë“¤)
model_paths = [f"{model_name}_fold{i+1}_best.pt" for i in range(folds)]

tta_transforms = [
    lambda x: x,
    lambda x: torch.flip(x, dims=[3]),
    lambda x: torch.flip(x, dims=[2]),
    lambda x: torch.rot90(x, k=1, dims=[2,3]),
    lambda x: torch.rot90(x, k=3, dims=[2,3])
]

preds_all = []
for path in model_paths:
    print(f"\nâ–¶ Loading {path}")
    # foldë§ˆë‹¤ ìƒˆ ëª¨ë¸ ê°ì²´ë¥¼ ë§Œë“¤ì–´ì£¼ê³  weightë¥¼ ë¡œë“œ
    # ì´ë¯¸ í•™ìŠµí•œ .pt íŒŒì¼ì— ê°€ì¤‘ì¹˜ê°€ ìˆìœ¼ë‹ˆê¹Œ, ë‹¤ì‹œ ImageNet weight ë¡œ ë¶ˆëŸ¬ì˜¬ í•„ìš” ì—†ìŒ
    model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)
    model.load_state_dict(torch.load(path, map_location=device))
    model.eval()

    preds_fold = []
    for images, _ in tqdm(tst_loader):
        images = images.to(device)
        tta_preds = []

        with torch.no_grad():
            for tta in tta_transforms:
                imgs_tta = tta(images)
                preds = model(imgs_tta)
                tta_preds.append(preds.softmax(dim=1).cpu().numpy())

        avg_preds = np.mean(tta_preds, axis=0)
        preds_fold.append(avg_preds)

    preds_fold = np.concatenate(preds_fold)
    preds_all.append(preds_fold)

# âœ… K-Fold í‰ê·  ì•™ìƒë¸”
avg_preds = np.mean(preds_all, axis=0)
final_preds = np.argmax(avg_preds, axis=1)

# âœ… í˜„ì¬ ì‹œê°„ ê¸°ë°˜ íŒŒì¼ëª… ìƒì„±
timestamp = datetime.datetime.now().strftime("%m%d_%H%M")
save_path = f"pred_{timestamp}.csv"

# âœ… ê²°ê³¼ ì €ì¥
tst_df = pd.read_csv("../data/sample_submission.csv")
tst_df["target"] = final_preds
tst_df.to_csv(save_path, index=False)

print(f"âœ… Saved submission: {save_path}")


# %%
