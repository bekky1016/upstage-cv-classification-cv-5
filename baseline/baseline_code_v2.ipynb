{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 1. Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import wandb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, path, transform=None):\n",
    "        self.df = df.values if isinstance(df, pd.DataFrame) else pd.read_csv(df).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, epoch=None):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Train Epoch {epoch+1}\" if epoch is not None else \"Train\")\n",
    "    for image, targets in pbar:\n",
    "        image, targets = image.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "        targets_list.extend(targets.cpu().numpy())\n",
    "\n",
    "    # ---- epoch별 평균 계산 ----\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    # ---- wandb 로그 기록 ----\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "        \"lr\": optimizer.param_groups[0][\"lr\"],        # ✅ 학습률 로그 추가\n",
    "        \"epoch\": epoch + 1 if epoch is not None else 0\n",
    "    })\n",
    "\n",
    "    return {\"train_loss\": train_loss, \"train_acc\": train_acc, \"train_f1\": train_f1}\n",
    "\n",
    "\n",
    "# Validation용 함수 추가\n",
    "def valid_one_epoch(loader, model, loss_fn, device, epoch=None):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=f\"Valid Epoch {epoch+1}\" if epoch is not None else \"Valid\")\n",
    "        for image, targets in pbar:\n",
    "            image, targets = image.to(device), targets.to(device)\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "            targets_list.extend(targets.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    # ---- wandb 로그 기록 ----\n",
    "    wandb.log({\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "        \"epoch\": epoch + 1 if epoch is not None else 0\n",
    "    })\n",
    "\n",
    "    return {\"val_loss\": val_loss, \"val_acc\": val_acc, \"val_f1\": val_f1}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 2. Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = 'datasets_fin/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'resnet34' # 'resnet50' 'efficientnet-b0', ...\n",
    "model_name = 'efficientnet_b3'\n",
    "# model_name = 'convnext_tiny'\n",
    "# model_name = 'vit_base_patch16_224'\n",
    "# model_name = 'swin_tiny_patch4_window7_224'\n",
    "\n",
    "# training config\n",
    "img_size = 640 # 224, 640\n",
    "LR = 1e-3\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 3. Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [],
   "source": [
    "# augmentation을 위한 transform 코드\n",
    "trn_transform = A.Compose([\n",
    "    # 이미지 크기 조정\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    \n",
    "    # --- 실제 Test domain 대응 증강 ---\n",
    "    A.Rotate(limit=180, p=0.7),                     # 회전\n",
    "    A.HorizontalFlip(p=0.5),                        # 좌우 반전\n",
    "    A.VerticalFlip(p=0.3),                          # 상하 반전\n",
    "    A.RandomResizedCrop(height=img_size, width=img_size, scale=(0.8, 1.0), p=0.4),  # 크롭\n",
    "    A.MotionBlur(blur_limit=5, p=0.3),              # 블러\n",
    "    A.GaussNoise(var_limit=(10, 50), p=0.3),        # 노이즈\n",
    "    A.RandomBrightnessContrast(p=0.3),              # 밝기/대비\n",
    "    A.HueSaturationValue(p=0.2),                    # 색조 변형 (인쇄/조명 차이 대응)\n",
    "    \n",
    "    # images normalization\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    # numpy 이미지나 PIL 이미지를 PyTorch 텐서로 변환\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지 수: 1704\n",
      "target\n",
      "0     100\n",
      "1     100\n",
      "2     100\n",
      "3     100\n",
      "4     100\n",
      "5     100\n",
      "6     100\n",
      "7     102\n",
      "8     100\n",
      "9     100\n",
      "10    102\n",
      "11    100\n",
      "12    100\n",
      "13    100\n",
      "14    100\n",
      "15    100\n",
      "16    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(\"총 이미지 수:\", len(os.listdir(\"../data/train_balanced\")))\n",
    "print(\"총 이미지 수:\", len(os.listdir(\"../data/train_mod_balanced\")))\n",
    "# df = pd.read_csv(\"../data/train_balanced.csv\")\n",
    "df = pd.read_csv(\"../data/train_mod_balanced.csv\")\n",
    "print(df[\"target\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "INxdmsStop2L",
    "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
   },
   "outputs": [],
   "source": [
    "# --- ✅ K-Fold split으로 변경 ---\n",
    "# train_df = pd.read_csv(\"../data/train_balanced.csv\")\n",
    "train_df = pd.read_csv(\"../data/train_mod_balanced.csv\")\n",
    "\n",
    "folds = 5\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "# ✅ progressive resizing 헬퍼 추가\n",
    "def adjust_img_size(epoch):\n",
    "    if epoch < 30:\n",
    "        return 384\n",
    "    elif epoch < 45:\n",
    "        return 512\n",
    "    else:\n",
    "        return 640\n",
    "\n",
    "def update_transforms(new_size):\n",
    "    global trn_transform, tst_transform\n",
    "    trn_transform = A.Compose([\n",
    "        A.Resize(height=new_size, width=new_size),\n",
    "        A.Rotate(limit=90, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomResizedCrop(height=new_size, width=new_size, scale=(0.9, 1.0), p=0.3),\n",
    "        A.GaussNoise(var_limit=(10, 40), p=0.2),\n",
    "        A.RandomBrightnessContrast(p=0.3),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    tst_transform = A.Compose([\n",
    "        A.Resize(height=new_size, width=new_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "# ✅ fold별 학습 루프\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n===== Fold {fold+1}/{folds} =====\")\n",
    "\n",
    "    trn_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    trn_dataset = ImageDataset(trn_df, \"../data/train_balanced/\", transform=trn_transform)\n",
    "    val_dataset = ImageDataset(val_df, \"../data/train_balanced/\", transform=tst_transform)\n",
    "\n",
    "    trn_loader = DataLoader(trn_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    run_name = f\"{model_name}_fold{fold+1}_{datetime.datetime.now().strftime('%m%d_%H%M')}\"\n",
    "    wandb.init(project=\"document-type-classification\", name=run_name)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        new_size = adjust_img_size(epoch)\n",
    "        update_transforms(new_size)\n",
    "        print(f\"\\n[Fold {fold+1}] [Epoch {epoch+1}] 이미지 크기 조정: {new_size}px\")\n",
    "\n",
    "        train_metrics = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device, epoch=epoch)\n",
    "        val_metrics = valid_one_epoch(val_loader, model, loss_fn, device=device, epoch=epoch)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(\n",
    "            f\"[Fold {fold+1}] [Epoch {epoch+1}/{EPOCHS}] \"\n",
    "            f\"Train F1: {train_metrics['train_f1']:.4f}, \"\n",
    "            f\"Val F1: {val_metrics['val_f1']:.4f}, \"\n",
    "            f\"LR: {optimizer.param_groups[0]['lr']:.8f}\"\n",
    "        )\n",
    "\n",
    "    model_path = f\"{model_name}_fold{fold+1}.pt\"\n",
    "    # torch.save(model.state_dict(), f\"model_fold{fold+1}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"✅ 모델 저장 완료: {model_path}\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 4. Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 5. Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12776,
     "status": "ok",
     "timestamp": 1700315185336,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "uRYe6jlPU_Om",
    "outputId": "2a08690c-9ffe-418d-8679-eb9280147110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TTA Inference 시작 =====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m===== TTA Inference 시작 =====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# ✅ test dataset / loader 정의\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m tst_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mImageDataset\u001b[49m(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/sample_submission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/test/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     transform\u001b[38;5;241m=\u001b[39mtst_transform\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m tst_loader \u001b[38;5;241m=\u001b[39m DataLoader(tst_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# ✅ fold별 모델 경로 지정 (이미 학습 완료된 모델들)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# --- ✅ 모든 Fold 학습 완료 후 Inference 단계 ---\n",
    "print(\"\\n===== TTA Inference 시작 =====\")\n",
    "\n",
    "# ✅ test dataset / loader 정의\n",
    "tst_dataset = ImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    transform=tst_transform\n",
    ")\n",
    "tst_loader = DataLoader(tst_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# ✅ fold별 모델 경로 지정 (이미 학습 완료된 모델들)\n",
    "model_paths = [f\"{model_name}_fold{i+1}.pt\" for i in range(folds)]\n",
    "\n",
    "tta_transforms = [\n",
    "    lambda x: x,\n",
    "    lambda x: torch.flip(x, dims=[3]),\n",
    "    lambda x: torch.flip(x, dims=[2]),\n",
    "    lambda x: torch.rot90(x, k=1, dims=[2,3]),\n",
    "    lambda x: torch.rot90(x, k=3, dims=[2,3])\n",
    "]\n",
    "\n",
    "preds_all = []\n",
    "for path in model_paths:\n",
    "    print(f\"\\n▶ Loading {path}\")\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    preds_fold = []\n",
    "    for images, _ in tqdm(tst_loader):\n",
    "        images = images.to(device)\n",
    "        tta_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for tta in tta_transforms:\n",
    "                imgs_tta = tta(images)\n",
    "                preds = model(imgs_tta)\n",
    "                tta_preds.append(preds.softmax(dim=1).cpu().numpy())\n",
    "\n",
    "        avg_preds = np.mean(tta_preds, axis=0)\n",
    "        preds_fold.append(avg_preds)\n",
    "\n",
    "    preds_fold = np.concatenate(preds_fold)\n",
    "    preds_all.append(preds_fold)\n",
    "\n",
    "# ✅ K-Fold 평균 앙상블\n",
    "avg_preds = np.mean(preds_all, axis=0)\n",
    "final_preds = np.argmax(avg_preds, axis=1)\n",
    "\n",
    "# ✅ 현재 시간 기반 파일명 생성\n",
    "timestamp = datetime.datetime.now().strftime(\"%m%d_%H%M\")\n",
    "save_path = f\"pred_{timestamp}.csv\"\n",
    "\n",
    "# ✅ 결과 저장\n",
    "tst_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "tst_df[\"target\"] = final_preds\n",
    "tst_df.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved submission: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best fold만 가지고 추론하는 방법\n",
    "best_fold = 2\n",
    "best_model_path = f\"{model_name}_fold{best_fold}_best.pt\"\n",
    "\n",
    "model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 단일 모델 추론\n",
    "preds_all = []\n",
    "for images, _ in tqdm(tst_loader):\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(images)\n",
    "        preds_all.append(preds.softmax(dim=1).cpu().numpy())\n",
    "\n",
    "avg_preds = np.concatenate(preds_all)\n",
    "final_preds = np.argmax(avg_preds, axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
